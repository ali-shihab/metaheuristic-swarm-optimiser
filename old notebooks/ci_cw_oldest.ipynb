{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIPoJSPyO0sE"
      },
      "source": [
        "# My Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "62Fv3eWKZoSu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import ConcatDataset, Subset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_NnYwFIg53C"
      },
      "source": [
        "# Seed for Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV1Kv89DHRoW",
        "outputId": "c61729c8-c3a3-4b22-b06c-c36433fc55f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78726c9d71d0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jWDU4lgbZuGM"
      },
      "outputs": [],
      "source": [
        "# define the CNN architecture\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, dropout_prob):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 32, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(32)\n",
        "        self.fc1 = nn.Linear(32 * 32, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 32 * 32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0Y_VhUWit2xa"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "# DATA PREPROCESSING\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataset, indices, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[self.indices[idx]]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# define normalisation\n",
        "def calc_mean_std(dataset):\n",
        "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "    mean_sum = 0.\n",
        "    var_sum = 0.\n",
        "    total_images_count = 0\n",
        "    for images, _ in dataloader:\n",
        "        batch_samples = images.size(0)\n",
        "        images = images.view(batch_samples, images.size(1), -1)\n",
        "        mean_sum += images.mean(2).sum(0)\n",
        "        var_sum += images.var(2).sum(0)\n",
        "        total_images_count += batch_samples\n",
        "\n",
        "    mean = mean_sum / total_images_count\n",
        "    var = var_sum / total_images_count\n",
        "    std = np.sqrt(var)\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "# Define transformations for data augmentation\n",
        "def train_transform(data, mean, std):\n",
        "  data = normalize(data, mean, std)\n",
        "  transform = transforms.Compose([\n",
        "                                transforms.RandomHorizontalFlip(0.25),\n",
        "                                transforms.RandomVerticalFlip(0.25),\n",
        "                                transforms.RandomGrayscale(0.25),\n",
        "                                transforms.RandomCrop(32, padding=4)\n",
        "                                 ])\n",
        "  return transform(data)\n",
        "\n",
        "# Define normalisation\n",
        "def normalize(data, mean, std):\n",
        "  transform = transforms.Compose([\n",
        "                                transforms.Normalize(mean, std)\n",
        "                                ])\n",
        "  return transform(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OyPC4tWRp-XR"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n",
        "    torch.save(state, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "82P35TRdVpN-"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "\n",
        "# Define function for training and evaluating the model\n",
        "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, mean, std, epochs=30):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    # train\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, train_load_labels in train_loader:\n",
        "            inputs = train_transform(inputs, mean, std)\n",
        "            inputs, train_load_labels = inputs.to(device), train_load_labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, train_load_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += train_load_labels.size(0)\n",
        "            correct += (predicted == train_load_labels).sum().item()\n",
        "            print(f'Batch Average Loss: {running_loss/total:.4f} Batch Accuracy {100*correct/total:.4f}')\n",
        "\n",
        "        epoch_loss = running_loss / total\n",
        "        epoch_accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}] Loss: {loss.item():.4f} Accuracy {epoch_accuracy:.4f}')\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # validate\n",
        "    # Early stopping parameters\n",
        "    early_stopping_patience = 10  # Number of epochs to wait for improvement before stopping\n",
        "    early_stopping_counter = 0    # Counter for epochs without improvement\n",
        "    best_accuracy = 0             # Track the best loss\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, test_load_labels in test_loader:\n",
        "            inputs = normalize(inputs, mean, std)\n",
        "            inputs, test_load_labels = inputs.to(device), test_load_labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += test_load_labels.size(0)\n",
        "            correct += (predicted == test_load_labels).sum().item()\n",
        "            validation_accuracy = 100 * correct / total\n",
        "\n",
        "            # Check if the current validation loss is better (lower) than the best recorded loss\n",
        "            if validation_accuracy > best_accuracy:\n",
        "                best_accuracy = validation_accuracy\n",
        "                early_stopping_counter = 0  # Reset the counter\n",
        "                # Save the model checkpoint\n",
        "                save_checkpoint({\n",
        "                    'epoch': epoch + 1,\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                }, filename=f\"best_model_epoch_{epoch+1}.pth.tar\")\n",
        "            else:\n",
        "                early_stopping_counter += 1\n",
        "\n",
        "            # Check if early stopping is triggered\n",
        "            if early_stopping_counter >= early_stopping_patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    return model\n",
        "\n",
        "def test(model, test_loader, mean, std):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, test_load_labels in test_loader:\n",
        "            inputs = normalize(inputs, mean, std)\n",
        "            inputs, test_load_labels = inputs.to(device), test_load_labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += test_load_labels.size(0)\n",
        "            correct += (predicted == test_load_labels).sum().item()\n",
        "\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RghE-KgmZ91b",
        "outputId": "5427cc2f-a4bf-4098-de2f-d695cecc660a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 62972565.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# dataset hyperparameters\n",
        "num_folds = 10\n",
        "test_size = 0.20\n",
        "batch_size = 64\n",
        "\n",
        "# load CIFAR-10 dataset & convert to tensor\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                             download=True,\n",
        "                                         transform=transforms.ToTensor())\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                            download=True,\n",
        "                                        transform=transforms.ToTensor())\n",
        "\n",
        "# combine train and test datasets for stratified splitting\n",
        "combined_set = ConcatDataset([train_set, test_set])\n",
        "\n",
        "# STRATIFIED SPLIT\n",
        "# collect the labels\n",
        "labels = [y for _, y in combined_set]\n",
        "\n",
        "# stratified split subset indices\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
        "train_idx, test_idx = next(sss.split(np.zeros(len(labels)), labels))\n",
        "\n",
        "# subset using indices & collect associated labels\n",
        "stratified_train_set, stratified_train_labels = Subset(combined_set, train_idx).dataset, [labels[i] for i in range(len(labels)) if i in train_idx]\n",
        "stratified_test_set, stratified_test_labels = Subset(combined_set, test_idx).dataset, [labels[i] for i in range(len(labels)) if i in test_idx]\n",
        "\n",
        "# create StratifiedKFold object for train set only\n",
        "skf = StratifiedKFold(n_splits=num_folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the best model\n",
        "# best_checkpoint = torch.load(\"best_model_epoch_X.pth.tar\")  # Replace X with the epoch number\n",
        "# model.load_state_dict(best_checkpoint['state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "t8pu_QfAabSj",
        "outputId": "ce1c001a-3ba8-49d4-c649-f8f2d3fb77b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1/10\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-59938221d322>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-643af0faf747>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, train_loader, test_loader, criterion, optimizer, mean, std, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_load_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_load_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_load_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-4aba72fd4068>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 576]' is invalid for input of size 32768"
          ]
        }
      ],
      "source": [
        "# Model hyperparameters\n",
        "dropout_prob = 0.25\n",
        "num_epochs = 20\n",
        "\n",
        "# call function\n",
        "# Main loop for k-fold cross-validation\n",
        "for fold, (train_fold_indices, val_fold_indices) in enumerate(skf.split(train_idx, stratified_train_labels)):\n",
        "    print(f'Fold {fold + 1}/{num_folds}')\n",
        "    mean, std = calc_mean_std(Subset(stratified_train_set, train_fold_indices))\n",
        "\n",
        "    train_sampler = torch.utils.data.SubsetRandomSampler(train_fold_indices)\n",
        "    val_sampler = torch.utils.data.SubsetRandomSampler(val_fold_indices)\n",
        "\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset=stratified_train_set,\n",
        "        batch_size=batch_size,\n",
        "        sampler=train_sampler,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        dataset=stratified_train_set,\n",
        "        batch_size=batch_size,\n",
        "        sampler=val_sampler,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g)\n",
        "\n",
        "    model = Net(dropout_prob).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, mean, std, epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNt0Y4EYrQKb",
        "outputId": "f8c31327-a1fb-4b09-aab6-ce83b319b478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 76.85%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test model\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=stratified_test_set,\n",
        "    batch_size=batch_size,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g)\n",
        "\n",
        "test(model, test_loader, mean, std)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVg4fZKiPdR4",
        "outputId": "1de8e526-3e98-4642-9d03-91baa6fc62e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n",
            "torch.Size([16, 3, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "params = list(model.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # conv1's .weight"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
